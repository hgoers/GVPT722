[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "content/02-ols_basics.html",
    "href": "content/02-ols_basics.html",
    "title": "OLS Basics",
    "section": "",
    "text": "Warning\n\n\n\nTHIS IS A DRAFT."
  },
  {
    "objectID": "content/02-ols_basics.html#packages",
    "href": "content/02-ols_basics.html#packages",
    "title": "OLS Basics",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(ggdist)\nlibrary(poliscidata)\nlibrary(modelsummary)\n\n\nset.seed(1234)"
  },
  {
    "objectID": "content/02-ols_basics.html#regression-models",
    "href": "content/02-ols_basics.html#regression-models",
    "title": "OLS Basics",
    "section": "Regression models",
    "text": "Regression models\nThis week we are going to continue to look at how we can model the distribution of our outcome of interest using a single predictor.\nHere’s the general formula for a linear regression model with a single predictor:\n\\[\nY = \\beta_0 + \\beta_1X_1 + \\epsilon\n\\]\nLet’s work backwards to help build our intuition for this model. Let’s start with a modeled relationship between some outcome, \\(Y\\), and a predictor, \\(X_1\\):\n\\[\nY = 10 + 20X_1 + \\epsilon\n\\]\nThink of this as the true relationship between \\(Y\\) and \\(X_1\\).\n\n\n\n\n\n\nNote\n\n\n\nOut there in the real world we use modeling to attempt to find this true relationship. If only we had access to it!\n\n\n\nRandom error\nThis equation has two unknown variables: \\(X_1\\) and \\(\\epsilon\\). You need both to be able to calculate the corresponding values for \\(Y\\).\n\\(X_1\\) will in many ways be more intuitive for you. Generally, it represents some vector of values that representing something tangible: perhaps it’s a person’s age, a country’s GDP, or a binary value telling you whether or not a country is a democracy. The error term can be a bit more abstract, so let’s take a minute to look at it more closely.\n\n\n\n\n\n\nNote\n\n\n\nA quick note on notation! Generally, we will use capital letters (for example, \\(Y\\) and \\(X_1\\)) to denote vectors and lower case letters (for example, \\(y\\) and \\(x_1\\)) to denote single values (usually with another subscript telling us the observation to which that single value belongs).\nWhat is a vector? Here, I mean a series of values. In other words, it is a fancy term for some variable. The term comes from matrix algebra. A matrix with only one row or column is referred to as a vector. Think of it simply as one column (variable) or one row (unit of observation) of a dataframe.\nFor example, if our outcome of interest is whether or not an individual will vote in the next election, we might use data on whether or not survey respondents voted in the last election to study the predictors of voting. In this case, our vector \\(Y\\) will be a series of 1s and 0s describing whether or not each survey respondent voted in the last election.\n\n\nThe error term; on the other hand, is a set of random values. It captures all of the random things that inevitably muddy the relationship between our outcomes of interest and our predictors in the real world.\nWe can learn some useful things about the random error effecting our outcome of interest. For example, let’s say that the error in this true relationship is normally distributed with a mean of zero and a standard deviation of 50. In other words, there is some random noise in our data: \\(Y\\) does not always precisely equal \\(10 + 20X_1\\). Some random value will always be added to \\(10 + 20X_1\\). That value will be drawn randomly from this distribution:\n\nggplot(tibble(error = rnorm(1e6, mean = 0, sd = 50)), aes(x = error)) + \n  geom_density(fill = \"#A2E3C4\") + \n  theme_minimal()\n\n\n\n\nThe coloured area under that curve represents the probability that the corresponding error value (along the \\(x\\)-axis) will be drawn. This means that each error value randomly drawn is most likely to be a number around zero (where the curve peaks). It is very unlikely to be a number bigger than around 150 or smaller than around -150.\nNotably, this error value is completely independent of \\(X_1\\) and \\(Y\\) (you don’t need these values to work out your error value). To demonstrate, let’s draw some of those random error values from this distribution:\n\nrnorm(1, mean = 0, sd = 50)\n\n[1] -47.37963\n\n\n\nrnorm(1, mean = 0, sd = 50)\n\n[1] -84.53445\n\n\n\nrnorm(1, mean = 0, sd = 50)\n\n[1] -28.83643\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis semester we will talk a lot about the assumptions you are required to make when you fit a linear regression model. These include some assumptions about error, including its shape and uniformity."
  },
  {
    "objectID": "content/02-ols_basics.html#fitting-our-regression-model",
    "href": "content/02-ols_basics.html#fitting-our-regression-model",
    "title": "OLS Basics",
    "section": "Fitting our regression model",
    "text": "Fitting our regression model\nLet’s make \\(X_1\\) equal all the whole numbers between one and 100. We can take this vector and our random error and find 100 values of \\(Y\\):\n\nx_1 &lt;- 1:100\nerror &lt;- rnorm(100, mean = 0, sd = 50)\n\ndf &lt;- tibble(x_1 = x_1,\n             y = 10 + 20*x_1 + error)\n\ndf\n\n# A tibble: 100 × 2\n     x_1     y\n   &lt;int&gt; &lt;dbl&gt;\n 1     1 -17.0\n 2     2  78.2\n 3     3  44.3\n 4     4 184. \n 5     5  96.6\n 6     6 168. \n 7     7 174. \n 8     8 184. \n 9     9 139. \n10    10 205. \n# ℹ 90 more rows\n\n\nLet’s plot those:\n\nggplot(df, aes(x = x_1, y = y)) + \n  geom_point() + \n  theme_minimal()\n\n\n\n\nWhat is the line-of-best-fit? In other words, what is the line that minimizes the distance between itself and all of these points?\n\nm &lt;- lm(y ~ x_1, data = df)\n\nsummary(m)\n\n\nCall:\nlm(formula = y ~ x_1, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-135.372  -28.844   -1.649   31.502  109.694 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   8.0917     9.9769   0.811    0.419    \nx_1          20.0844     0.1715 117.098   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 49.51 on 98 degrees of freedom\nMultiple R-squared:  0.9929,    Adjusted R-squared:  0.9928 \nF-statistic: 1.371e+04 on 1 and 98 DF,  p-value: &lt; 2.2e-16\n\n\nHmm, it’s different from the true relationship. It’s this:\n\\[\nY = 8.09 + 20.08X_1 + \\epsilon\n\\]\nInstead of this:\n\\[\nY = 10 + 20X_1 + \\epsilon\n\\]\nThis is despite the fact that we set everything up according to the true relationship between \\(Y\\) and \\(X_1\\)!\nWhy is it different? The long and short answer is: that pesky random error!\nRandom error will always exist. That’s okay. That’s why we built it into our true relationship. We have some statistical tools to help us deal out.\nLooking back at our model’s output we can see that we are provided with a lot of information about its uncertainty in those coefficient estimates.\n\ntidy(m)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic   p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)     8.09     9.98      0.811 4.19e-  1\n2 x_1            20.1      0.172   117.    4.05e-107\n\n\nIn addition to our coefficient estimates (estimate), we also have access to each estimate’s standard error (std.error), t-statistic (statistic), and p-value (p.value). Let’s focus on the standard error. We can use this to work out all of the plausible alternative coefficient estimates that our model could have found if that random error had been different. Let’s take a look at those plausible alternatives to see whether the true relationship (\\(\\beta_0 = 10\\) and \\(\\beta_1 = 20\\)) is sitting in there.\nLet’s start with the intercept. Centering our plausible set of intercept estimates on our model’s best guess - 8.09 - let’s simulate those alternative estimates using our uncertainty (the intercept coefficient’s standard error) and see where the “true” intercept estimate (represented by the black line on the graph below) sits within this context:\n\nintercept_est &lt;- tidy(m) |&gt; \n  filter(term == \"(Intercept)\") |&gt; \n  pull(estimate)\n\nintercept_est\n\n[1] 8.091687\n\nintercept_se &lt;- tidy(m) |&gt; \n  filter(term == \"(Intercept)\") |&gt; \n  pull(std.error)\n\nintercept_se\n\n[1] 9.976851\n\n\n\ntibble(intercept = rnorm(1e6, mean = intercept_est, sd = intercept_se)) |&gt; \n  ggplot(aes(x = intercept)) + \n  stat_halfeye(.width = c(0.025, 0.975), fill = \"#A2E3C4\") +\n  geom_vline(xintercept = 10) + \n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nI expect these plausible alternative coefficients to be normally distributed. For a simulated proof of why we can assume this, please check out the Regression notes from GVPT622.\n\n\nWe can do the same for our model’s best guess of \\(\\beta_1\\):\n\nbeta_1_est &lt;- tidy(m) |&gt; \n  filter(term == \"x_1\") |&gt; \n  pull(estimate)\n\nbeta_1_est\n\n[1] 20.08444\n\nbeta_1_se &lt;- tidy(m) |&gt; \n  filter(term == \"x_1\") |&gt; \n  pull(std.error)\n\nbeta_1_se\n\n[1] 0.1715183\n\n\n\ntibble(beta_1 = rnorm(1e6, mean = beta_1_est, sd = beta_1_se)) |&gt; \n  ggplot(aes(x = beta_1)) + \n  stat_halfeye(.width = c(0.025, 0.975), fill = \"#3095A2\") +\n  geom_vline(xintercept = 20) + \n  theme_minimal()\n\n\n\n\nOften in political science we are required to accept that the true estimates sit somewhere with 95 percent of these alternatives. Happily for us, the true values for the intercept (10) and \\(\\beta_1\\) (20) sit within this range (shown by the horizontal black lines on the graphs)."
  },
  {
    "objectID": "content/02-ols_basics.html#statistical-significance",
    "href": "content/02-ols_basics.html#statistical-significance",
    "title": "OLS Basics",
    "section": "Statistical significance",
    "text": "Statistical significance\nTraditionally, we are required to accept that 95 percent of all alternative coefficient estimates are plausible. Sadly for us, zero is included within this range of plausible values for the intercept coefficient. This coefficient would not; therefore, be considered to be statistically significant at the 95 percent confidence level.\nWe can learn that more quickly using the intercept coefficient’s p-value (which is less than 0.05, or the 5 percent risk we are willing to take on that we believe a null relationship):\n\ntidy(m)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic   p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)     8.09     9.98      0.811 4.19e-  1\n2 x_1            20.1      0.172   117.    4.05e-107\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe p-value tells us how likely we would be to observe the coefficient estimate that we did if it were actually equal to zero. It is calculated using the coefficient estimate’s t-statistic (statistic), which is a transformation of the coefficient estimate into its place along a standard distribution: the t-distribution.\n\n\nWhat if we had more certainty around our estimates? In other words, what if there was less error? Let’s reduce the spread of our random error by reducing its standard deviation from 50 to 5:\n\nerror_smaller &lt;- rnorm(100, mean = 0, sd = 5)\n\ndf_smaller &lt;- tibble(x_1 = x_1,\n                     y = 10 + 20*x_1 + error_smaller)\n\ndf_smaller\n\n# A tibble: 100 × 2\n     x_1     y\n   &lt;int&gt; &lt;dbl&gt;\n 1     1  28.1\n 2     2  39.1\n 3     3  74.7\n 4     4  89.9\n 5     5 106. \n 6     6 131. \n 7     7 155. \n 8     8 166. \n 9     9 181. \n10    10 213. \n# ℹ 90 more rows\n\n\nLet’s plot that:\n\nggplot(df_smaller, aes(x = x_1, y = y)) + \n  geom_point() + \n  theme_minimal()\n\n\n\n\nThose data points are much more tightly placed around the line-of-best-fit. Let’s find that line:\n\nm_smaller &lt;- lm(y ~ x_1, data = df_smaller)\n\nsummary(m_smaller)\n\n\nCall:\nlm(formula = y ~ x_1, data = df_smaller)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-10.351  -3.325  -0.249   3.777  10.456 \n\nCoefficients:\n            Estimate Std. Error  t value Pr(&gt;|t|)    \n(Intercept)   9.2587     1.0180    9.095 1.12e-14 ***\nx_1          20.0112     0.0175 1143.402  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.052 on 98 degrees of freedom\nMultiple R-squared:  0.9999,    Adjusted R-squared:  0.9999 \nF-statistic: 1.307e+06 on 1 and 98 DF,  p-value: &lt; 2.2e-16\n\n\nOr:\n\\[\nY = 9.2587 + 20.0112X_1 + \\epsilon\n\\]\nThat’s closer to the true relationship! But - of course - there is still uncertainty in those estimates. Let’s look at the plausible range of intercept estimates:\n\nintercept_est_smaller &lt;- tidy(m_smaller) |&gt; \n  filter(term == \"(Intercept)\") |&gt; \n  pull(estimate)\n\nintercept_est_smaller\n\n[1] 9.258682\n\nintercept_se_smaller &lt;- tidy(m_smaller) |&gt; \n  filter(term == \"(Intercept)\") |&gt; \n  pull(std.error)\n\nintercept_se_smaller\n\n[1] 1.018022\n\n\n\ntibble(intercept = rnorm(1e6, mean = intercept_est_smaller, sd = intercept_se_smaller)) |&gt; \n  ggplot(aes(x = intercept)) + \n  stat_halfeye(.width = c(0.025, 0.975), fill = \"#A2E3C4\") +\n  geom_vline(xintercept = 10) + \n  theme_minimal()\n\n\n\n\nNo zero in sight! The range of values included within this plausible range is much smaller and it still includes the true intercept (10). By reducing our uncertainty, we gained more confident insight into where the true intercept coefficient lies.\n\n\n\n\n\n\nTip\n\n\n\nThis is an important point to think about: we lost the zero because the true intercept is different from zero. Sometimes you will theorize that changes to a predictor are associated with changes to your outcome of interest. Sometimes the truth is that there is no meaningful relationship between the two. We can learn a lot from strong null results. You should always aim to reduce your uncertainty, even if it leads to a stronger zero."
  },
  {
    "objectID": "content/02-ols_basics.html#interpreting-your-regression-models",
    "href": "content/02-ols_basics.html#interpreting-your-regression-models",
    "title": "OLS Basics",
    "section": "Interpreting your regression models",
    "text": "Interpreting your regression models\nWe use regression models to provide empirical evidence of the relationship between our outcome of interest and a set of predictors that we theorize to be important drivers of that outcome.\nRegression models cannot prove causality. This can make them difficult or awkward to interpret. You need to be very careful with the language you use to describe your model to avoid being misleading.\nLet’s step through interpreting your model results. To do this, we will look at the (highly precise) relationship between an individual’s feelings towards President Obama and their dog ownership.\nThe National Election Survey (NES) asked respondents both their feelings towards President Obama (rating between zero and 100, with higher values indicating more support) and whether or not they own a dog. Let’s fit a linear regression model against their responses to these two questions:\n\nm &lt;- lm(obama_therm ~ own_dog, data = nes)\n\nmodelsummary(m,\n             statistic = \"[{conf.low}, {conf.high}]\",\n             stars = T,\n             coef_rename = c(\"own_dogYes\" = \"Owns a dog\"))\n\n\n\n\n\n (1)\n\n\n\n\n(Intercept)\n74.305***\n\n\n\n[72.505, 76.104]\n\n\nOwns a dog\n−9.286***\n\n\n\n[−12.005, −6.566]\n\n\nNum.Obs.\n1927\n\n\nR2\n0.023\n\n\nR2 Adj.\n0.022\n\n\nAIC\n18606.2\n\n\nBIC\n18622.8\n\n\nLog.Lik.\n−9300.077\n\n\nRMSE\n30.18\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n\n\nOur regression model is as follows:\n\\[\nObama\\ thermometer = 74.3047 - 9.2858*Owns\\ a\\ dog + \\epsilon\n\\]\nIt is tempting to state that the estimated effect of dog ownership on an individual’s feelings towards Obama is a decrease of 9.28 points, on average and holding all else constant. However, this suggests an effect for which we really have no proof. According to Gelman, Hill, and Vehtari (2020), an effect is usually thought of as “the change associated with some treatment, or intervention” (pg. 84). Here, we would be suggesting that if we gave someone a dog, their support for Obama would drop by 9.28 points. That’s not actually what we have found. Rather, we have observed that, on average, people who were surveyed who had a dog had lower opinions of Obama than those who did not own a dog.\nAnother way of thinking about this is to acknowledge that regression models using observational data only allow us to make comparisons between our units of observation. Here, we can make comparisons between respondents to the NES. We cannot, however, use this model to make statements about changes to any individual respondent. The NES did not give someone a dog and then ask them how their feelings towards Obama changed. We cannot suggest that we have insight into the effects of such an intervention (as cute as it would be).\nWhen you are interpreting a regression model, you should use comparative language. For example, we can say that, under the fitted model, the average difference in feelings towards President Obama between a person with a dog and a person without a dog is 9.28 points.\n\n\n\n\n\n\nTip\n\n\n\nThis care with your language will become even more important when we move on to looking at multiple predictors.\n\n\nRemember: regression is just fancy averaging. This binary predictor makes this point easy to illustrate. For example, let’s look at how we can interpret the intercept. Individuals who do not own a dog (own_dog \\(= 0\\)) are predicted to report feeling 74.3 points towards President Obama, on average and holding all else constant.\nWhere did this come from, you may ask? It’s just fancy averaging!\n\navg_responses &lt;- nes |&gt; \n  drop_na(own_dog) |&gt; \n  group_by(own_dog) |&gt; \n  summarise(avg_obama_therm = mean(obama_therm, na.rm = T))\n\navg_responses\n\n# A tibble: 2 × 2\n  own_dog avg_obama_therm\n  &lt;fct&gt;             &lt;dbl&gt;\n1 No                 74.3\n2 Yes                65.0\n\n\nThere it is! It’s just the average response provided by those who do not own a dog. How cool is that?!\nYou may also have noticed that the difference between the average response provided by dog owners and non-dog owners is roughly 9 points. Hmm…\n\nmutate(avg_responses, diff = avg_obama_therm - lag(avg_obama_therm))\n\n# A tibble: 2 × 3\n  own_dog avg_obama_therm  diff\n  &lt;fct&gt;             &lt;dbl&gt; &lt;dbl&gt;\n1 No                 74.3 NA   \n2 Yes                65.0 -9.29\n\n\nThat’s our coefficient estimate! It’s just the difference in the average response provided by dog owners and non-dog owners.\nThis is the beauty of linear regression: we can gain so much insight into the important predictors of the things that we really care about by applying simple and clear statistical processes to our data."
  },
  {
    "objectID": "content/02-ols_basics.html#making-predictions-using-your-regression-model",
    "href": "content/02-ols_basics.html#making-predictions-using-your-regression-model",
    "title": "OLS Basics",
    "section": "Making predictions using your regression model",
    "text": "Making predictions using your regression model\nThis leads us neatly to another great use for our regression model: predictions. We can use our model to predict our outcome of interest.\nFor example, imagine that I pulled someone randomly from the US voting population and asked them their feelings towards President Obama on a 100-point scale. What would be your best guess of their response?\nWe have access to the NES, which is a representative sample of the US voting population. In other words, they pulled 5,916 people randomly from the US voting population and asked them this very question. We can look at the first 10 respondents’ answers:\n\nhead(nes$obama_therm, n = 10)\n\n [1]  15 100  70  30  70  45  50  60  15 100\n\n\nImagine that the only information I provide to you is these 5,916 individuals’ responses. Your educated best guess may then be the average of their response:\n\nmean(nes$obama_therm, na.rm = T)\n\n[1] 60.74377\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nIt’s just fancy averaging!\n\nlm(obama_therm ~ 1, data = nes)\n\n\nCall:\nlm(formula = obama_therm ~ 1, data = nes)\n\nCoefficients:\n(Intercept)  \n      60.74  \n\n\n\n\n\nNow I might ask you what other piece of information you would like to know about this random individual that might improve your guess. You may respond that you would like to know whether or not they identify as a Democrat. You suspect that Democrats will have warmer feelings towards Obama than non-Democrats.\nYou adopt the same approach (your best guess is the average response), but you can now look at Democrats and non-Democrats separately.\n\nobama_therm_dem &lt;- nes |&gt; \n  group_by(dem) |&gt; \n  summarise(avg_obama_therm = mean(obama_therm, na.rm = T))\n\nobama_therm_dem\n\n# A tibble: 3 × 2\n    dem avg_obama_therm\n  &lt;dbl&gt;           &lt;dbl&gt;\n1     0            44.2\n2     1            85.3\n3    NA            65.7\n\n\nNow your best guess may be 85.31 if the random person identifies as a Democrat and 44.24 if they do not.\n\n\n\n\n\n\nTip\n\n\n\n\n\nIt’s just fancy averaging!\n\nlm(obama_therm ~ dem, data = nes)\n\n\nCall:\nlm(formula = obama_therm ~ dem, data = nes)\n\nCoefficients:\n(Intercept)          dem  \n      44.24        41.06  \n\n\nRemember, the coefficient estimate for dem is the estimated difference between individuals who do not identify as Democrats (dem \\(= 0\\)) and individuals who identify as Democrats (dem \\(= 1\\)). In other words, add those two values together and you will get the average response provided by Democrats: 85.31.\n\n\n\nHave you improved your guess? How might we evaluate this? One approach would be to look at how far our predicted values were from the observed values.\nUsing our most simple approach, we will always predict the average feeling thermometer value provided by respondents to the NES. Using our slightly more sophisticated approach, we will predict the average response provided by Democrats if the individual is a Democrat, or the average response provided by non-Democrats if they do not identify as a Democrat. Let’s map those predictions against the actual responses provided by NES participants:\n\npred &lt;- nes |&gt; \n  transmute(dem, \n            obama_therm,\n            pred_simple = mean(nes$obama_therm, na.rm = T)) |&gt; \n  left_join(obama_therm_dem) |&gt; \n  rename(pred_party_id = avg_obama_therm)\n\npred |&gt; \n  select(dem, obama_therm, pred_simple, pred_party_id) |&gt; \n  head()\n\n  dem obama_therm pred_simple pred_party_id\n1   0          15    60.74377      44.24474\n2   1         100    60.74377      85.30587\n3   0          70    60.74377      44.24474\n4   1          30    60.74377      85.30587\n5   0          70    60.74377      44.24474\n6   0          45    60.74377      44.24474\n\n\nHere, we have stored our simple prediction in the pred_simple variable and our approach that accounts for party identification in the pred_party_id column.\nHow does each approach perform?\n\npred |&gt; \n  mutate(resid_simple = pred_simple - obama_therm,\n         resid_party_id = pred_party_id - obama_therm) |&gt; \n  summarise(r_2_simple = sum(resid_simple^2, na.rm = T),\n            r_2_party_id = sum(resid_party_id^2, na.rm = T))\n\n  r_2_simple r_2_party_id\n1    6582137      4364116\n\n\nThe simple approach predicts values further from the observed values than our approach that accounts for party ID. Great! It is worthwhile asking our random individual to which party they belong.\nSoon, we will look at including more than one predictor in our models. This will help us improve our predictive power even further."
  },
  {
    "objectID": "content/01-introduction.html",
    "href": "content/01-introduction.html",
    "title": "Linear Regression: A Refresher",
    "section": "",
    "text": "library(tidyverse)\nlibrary(poliscidata)\nlibrary(janitor)\nlibrary(scales)\nlibrary(wbstats)\nlibrary(broom)\nlibrary(ggdist)"
  },
  {
    "objectID": "content/01-introduction.html#packages",
    "href": "content/01-introduction.html#packages",
    "title": "Linear Regression: A Refresher",
    "section": "",
    "text": "library(tidyverse)\nlibrary(poliscidata)\nlibrary(janitor)\nlibrary(scales)\nlibrary(wbstats)\nlibrary(broom)\nlibrary(ggdist)"
  },
  {
    "objectID": "content/01-introduction.html#introduction",
    "href": "content/01-introduction.html#introduction",
    "title": "Linear Regression: A Refresher",
    "section": "Introduction",
    "text": "Introduction\nYou have a brilliant idea describing the relationship between an outcome of interest and a variable that you think is driving interesting changes to that outcome. You have a very clever theory describing the relationship between these two phenomena. Now you want to provide empirical support for that theory.\nThis quick refresher will outline the steps required to fit a linear regression model against two continuous variables: a dependent variable (our outcome of interest) and an independent variable (the thing you think is driving changes to that outcome of interest).\n\n\n\n\n\n\nNote\n\n\n\nFor a more in-depth set of notes on each of these steps, please refer to the GVPT622: Quantitative Methods for Political Science notes."
  },
  {
    "objectID": "content/01-introduction.html#do-richer-countries-enjoy-better-health-outcomes",
    "href": "content/01-introduction.html#do-richer-countries-enjoy-better-health-outcomes",
    "title": "Linear Regression: A Refresher",
    "section": "Do richer countries enjoy better health outcomes?",
    "text": "Do richer countries enjoy better health outcomes?\nLet’s return to a familiar question: what is the relationship between a country’s health and its wealth?\nHere, our outcome of interest is the average health of countries’ citizens. We want to determine what factors are important determinants of a country’s citizens’ health. We theorize that the level of wealth each country’s citizens hold is an important determinant of their overall health.\nSimply put, our goal is to produce the best model we can of how our outcome of interest occurs. You might hear people refer to this process - how an outcome of interest occurs - as the data generation process. This is just a rather sterile way of asking how our outcome of interest comes to be. For example, what factors drove the level of health of countries last year? How did they shape those health outcomes?\nWe can use a good model of our outcome of interest to achieve two worthwhile goals. First, this model provides us with explanatory traction. This, generally speaking, is your raison d’être as an academic. Your research goals should be to identify and explain the mechanisms driving changes to some important outcome of interest. To do that, you need to identify what factors are the important determinants of that outcome of interest. What gets people out to vote? What drives countries to war with one another? Why do some countries experience democratic backsliding? You need to find and then explain what factors are the most important drivers of these outcomes. You can use these statistical tools to do just that.\nSecond, this model provides us with predictive power. If we know the factors that are driving (or at least strongly associated with) changes to our outcome of interest and we know how they are shaping that outcome, we can predict how changes to those factors will effect our outcome of interest. For example, if you know that large spikes in the price of food staples are strongly associated with the onset of civil unrest, you can alert policymakers to the increased risk of that unrest if such spikes occur. You can also use your model to inform policymakers of the expected effects of various policies or interventions that they may be considering.\nHaving completed GVPT622, you now have the knowledge and skills to test empirically the relationship between two variables: a dependent and an independent variable. Let’s refresh those."
  },
  {
    "objectID": "content/01-introduction.html#step-1-collect-your-data",
    "href": "content/01-introduction.html#step-1-collect-your-data",
    "title": "Linear Regression: A Refresher",
    "section": "Step 1: Collect your data",
    "text": "Step 1: Collect your data\nDo richer countries enjoy better health outcomes? To answer this question, we need data on the health and wealth of each country’s citizens. We will use historical data to learn about the relationship between a country’s health and wealth. We will then extrapolate from that historical relationship to a generalized understanding of the relationship.\nTo do this, we need an observable and measurable factor that appropriately represents each of these concepts. I propose to follow the approach applied by the Gapminder project. We will use the average life expectancy of each country’s citizens as a measure of the health of its citizens. Countries with higher average life expectancy are assumed to have higher levels of health. We will use each country’s gross domestic product (GDP) per capita as our proxy measure of its citizens’ average wealth. Countries with higher GDP per capita are assumed to have wealthier citizens.\nWe might expect that as the wealth of country’s citizens increases, so too does their overall health. Our measurable hypothesis is; therefore, as follows:\n\nThe higher a country’s GDP per capita, the longer its average life expectancy will be.\n\n\n\n\n\n\n\nTip\n\n\n\nAll hypotheses must be testable. In other words, we must be able to use data to prove whether or not our hypothesis is true or false.\n\n\nThe World Bank provides reliable data on both of these variables. We can use the wbstats R package to pull these data from the World Bank API all from within our R script.\n\ngapminder_df &lt;- wb_data(\n  indicator = c(\"SP.DYN.LE00.IN\", \"NY.GDP.PCAP.CD\"),\n  start_date = 2021,\n  end_date = 2021\n) |&gt; \n  rename(\n    life_exp = SP.DYN.LE00.IN,\n    gdp_per_cap = NY.GDP.PCAP.CD\n  ) |&gt; \n  mutate(log_gdp_per_cap = log(gdp_per_cap)) \n\ngapminder_df\n\n# A tibble: 217 × 7\n   iso2c iso3c country               date gdp_per_cap life_exp log_gdp_per_cap\n   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;                &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;           &lt;dbl&gt;\n 1 AW    ABW   Aruba                 2021      29128.     74.6           10.3 \n 2 AF    AFG   Afghanistan           2021        356.     62.0            5.87\n 3 AO    AGO   Angola                2021       1927.     61.6            7.56\n 4 AL    ALB   Albania               2021       6377.     76.5            8.76\n 5 AD    AND   Andorra               2021      42072.     NA             10.6 \n 6 AE    ARE   United Arab Emirates  2021      44332.     78.7           10.7 \n 7 AR    ARG   Argentina             2021      10651.     75.4            9.27\n 8 AM    ARM   Armenia               2021       4973.     72.0            8.51\n 9 AS    ASM   American Samoa        2021      16654.     NA              9.72\n10 AG    ATG   Antigua and Barbuda   2021      17179.     78.5            9.75\n# ℹ 207 more rows"
  },
  {
    "objectID": "content/01-introduction.html#step-2-know-your-data",
    "href": "content/01-introduction.html#step-2-know-your-data",
    "title": "Linear Regression: A Refresher",
    "section": "Step 2: Know your data",
    "text": "Step 2: Know your data\nOnce you have data for your variables of interest you should take a good look at them. We now have access to data on 217 countries’ average life expectancy and GDP per capita.\n\nIndividual variables\nFirst, take a look at each variable individually. Some useful questions with which to start include:\n\nWhat kind of data are they (continuous or categorical)?\nHow are they distributed (normally or are they skewed)?\nAre there any unusual data points? If so, why are they unusual?\nAre any observations missing? Is this missingness random or systematic?\n\nOne of the easiest ways to answer these and other important questions is by visualizing your variables. We can use the many great plot functions in ggplot to do this.\nLet’s start with our outcome of interest: a country’s average life expectancy.\n\nggplot(gapminder_df, aes(x = life_exp)) + \n  geom_histogram() + \n  theme_minimal() + \n  labs(\n    x = \"Average life expectancy (in years)\",\n    y = \"Count\"\n  )\n\n\n\n\nThis is what we are trying to model.\nWe suspect that the average wealth of a country’s citizens is associated with their overall level of health. Let’s look at the distribution of countries’ GDP per capita:\n\nggplot(gapminder_df, aes(x = gdp_per_cap)) + \n  geom_histogram() + \n  theme_minimal() + \n  labs(\n    x = \"GDP per capita (in current USD)\",\n    y = \"Count\"\n  ) + \n  scale_x_continuous(labels = label_dollar())\n\n\n\n\n\n\nThe relationship between these two variables\nNow you can take a look at the relationship between your two variables of interest.\nSome good questions with which to start:\n\nHow do the two variables move with each other? As one goes up, does the other also go up, go down, or stay roughly constant?\nWhat is the shape of this relationship? Is it constant (linear)?\nAre there any noticable clusters or groups of observations?\nAre there any unusual observations? Ones sitting out on their own?\n\nLet’s visualize the relationship between each country’s average life expectancy and its GDP per capita:\n\nggplot(gapminder_df, aes(x = gdp_per_cap, y = life_exp)) + \n  geom_point() + \n  theme_minimal() + \n  labs(x = \"GDP per capita (USD current)\",\n       y = \"Average life expectancy (years)\") + \n  scale_x_continuous(labels = label_dollar())\n\n\n\n\nThis relationship is positive: as a country’s wealth increases, so too does its health. However, this relationship is not linear. An increase of $1,000 GDP per capita tends to be associated with a large increase in the country’s average life expectancy when the country has relatively low GDP per capita compared to the change in a richer country’s average life expectancy that tends to be associated with that same $1,000 increase in GDP per capita.\nWe can model non-linear relationships; however, these models can be difficult to interpret. Happily the relationship between a country’s average life expectancy and its logged GDP per capita is linear:\n\nggplot(gapminder_df, aes(x = log_gdp_per_cap, y = life_exp)) + \n  geom_point() + \n  theme_minimal() + \n  labs(x = \"Logged GDP per capita\",\n       y = \"Average life expectancy (years)\") + \n  scale_x_continuous(labels = label_dollar())\n\n\n\n\nThis transformation means that we can now appropriately fit a linear model to these two variables: logged GDP per capita and average life expectancy."
  },
  {
    "objectID": "content/01-introduction.html#step-3-fit-your-linear-model",
    "href": "content/01-introduction.html#step-3-fit-your-linear-model",
    "title": "Linear Regression: A Refresher",
    "section": "Step 3: Fit your linear model",
    "text": "Step 3: Fit your linear model\nWe can now fit a linear regression model to our data to better capture and generalize this relationship.\n\nAn Ordinary Least Squares (OLS) regression finds the straight line that minimizes the distance between itself and all of the data points.\n\nWe can visualize that relationship using geom_smooth() from ggplot:\n\nggplot(gapminder_df, aes(x = log_gdp_per_cap, y = life_exp)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = F) + \n  theme_minimal() + \n  labs(x = \"Logged GDP per capita\",\n       y = \"Average life expectancy (years)\") + \n  scale_x_continuous(labels = label_dollar())\n\n\n\n\nWe can fit that model using lm():\n\nm &lt;- lm(life_exp ~ log_gdp_per_cap, data = gapminder_df)\n\nm\n\n\nCall:\nlm(formula = life_exp ~ log_gdp_per_cap, data = gapminder_df)\n\nCoefficients:\n    (Intercept)  log_gdp_per_cap  \n         33.427            4.316  \n\n\nThis gives us an estimated linear relationship between a country’s health and wealth. Formally:\n\\[\nLife\\ expectancy = \\beta_0 + \\beta_{1} Logged\\ GDP\\ per\\ capita + \\epsilon\n\\]\nOur model estimates the following relationship:\n\\[\nLife\\ expectancy = 33.427 + 4.316 Logged\\ GDP\\ per\\ capita + \\epsilon\n\\]\nWe can use this model to do all kinds of amazing things, including (hopefully) providing empirical support for our theories and making predictions about some outcome of interest."
  },
  {
    "objectID": "content/01-introduction.html#step-4-interpret-your-model",
    "href": "content/01-introduction.html#step-4-interpret-your-model",
    "title": "Linear Regression: A Refresher",
    "section": "Step 4: Interpret your model",
    "text": "Step 4: Interpret your model\nWhat does this model tell us about the estimated relationship between a country’s life expectancy and its logged GDP per capita?\nFirst, let’s look at the regression coefficient for a country’s logged GDP per capita. We found that every one unit increase in a country’s logged GDP per capita is associated with a 4.316 year increase in its citizens’ average life expectancy, on average.\nSecond, let’s look at that intercept coefficient. A country with a logged GDP per capita of zero is expected to have an average life expectancy of 33.427 years, on average. This is not a very useful piece of information because there are no countries with zero (logged) GDP per capita. Therefore, this intercept coefficient is more usefully thought of as a statistical artifact that grounds our model.\n\n\n\n\n\n\nWarning\n\n\n\nLinear regression models cannot detect causal relationships. You cannot use this model to determine whether changes to your dependent variable are caused by changes to your independent variable. Here, we cannot use this model as evidence of changes to a country’s GDP per capita causing changes in its average life expectancy. Therefore, you need to be careful when interpreting linear regression models. Use words like “associated with” instead of “causes”."
  },
  {
    "objectID": "content/01-introduction.html#step-5-evaluate-your-model",
    "href": "content/01-introduction.html#step-5-evaluate-your-model",
    "title": "Linear Regression: A Refresher",
    "section": "Step 5: Evaluate your model",
    "text": "Step 5: Evaluate your model\nHow well does our model fit our data? This is a complicated question without a single answer. As we step through this you should think critically about what questions you should ask of your data and your model that would help convince you that you have found the underlying relationship.\nThe first thing that is worth noting is that in the previous step we moved away from focusing on modelling our outcome of interest: each country’s average life expectancy. Instead, we wanted to understand the relationship between that outcome and our independent variable (each country’s GDP per capita). Let’s step back for a second and look again at modelling the outcome of interest.\nTo do this, we can see what our model predicts each country’s average life expectancy to be given its GDP per capita. To work this out, we simply need to plug each country’s GDP per capita into our model:\n\\[\nLife\\ expectancy = 33.427 + 4.316 Logged\\ GDP\\ per\\ capita + \\epsilon\n\\]\nHappily, broom::augment() does this for us:\n\nm_pred &lt;- augment(m)\nm_pred\n\n# A tibble: 202 × 9\n   .rownames life_exp log_gdp_per_cap .fitted .resid    .hat .sigma  .cooksd\n   &lt;chr&gt;        &lt;dbl&gt;           &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n 1 1             74.6           10.3     77.8 -3.17  0.00944   4.25 0.00268 \n 2 2             62.0            5.87    58.8  3.20  0.0255    4.25 0.00762 \n 3 3             61.6            7.56    66.1 -4.43  0.00887   4.25 0.00492 \n 4 4             76.5            8.76    71.2  5.22  0.00498   4.24 0.00380 \n 5 6             78.7           10.7     79.6 -0.898 0.0125    4.26 0.000287\n 6 7             75.4            9.27    73.5  1.94  0.00531   4.26 0.000558\n 7 8             72.0            8.51    70.2  1.88  0.00525   4.26 0.000519\n 8 10            78.5            9.75    75.5  2.98  0.00670   4.25 0.00167 \n 9 11            83.3           11.0     81.0  2.34  0.0154    4.26 0.00240 \n10 12            81.2           10.9     80.4  0.818 0.0142    4.26 0.000271\n# ℹ 192 more rows\n# ℹ 1 more variable: .std.resid &lt;dbl&gt;\n\n\naugment() takes each of our 217 countries’ logged GDP per capita (log_gdp_per_cap), plugs it into our model (written above), and tells us the corresponding predicted average life expectancy (.fitted).\n\n\n\n\n\n\nNote\n\n\n\nNote that some data are missing for some countries. That is why we have less than 217 predicted values.\n\n\nLet’s take a look at both our predicted average life expectancy and the actual average life expectancy of each country in our dataset:\n\nggplot(m_pred) + \n  geom_histogram(aes(x = life_exp)) + \n  geom_histogram(aes(x = .fitted), fill = \"blue\", alpha = 0.5) +\n  theme_minimal() + \n  labs(x = \"Average life expectancy (in years)\",\n       y = \"Count\")\n\n\n\n\nThe distribution of the predicted average life expectancy is provided in blue. The actual average life expectancy of each county is provided in gray.\nA density curve might also help here:\n\nggplot(m_pred) + \n  geom_density(aes(x = life_exp)) + \n  geom_density(aes(x = .fitted), colour = \"blue\") +\n  theme_minimal() + \n  labs(x = \"Average life expectancy (in years)\",\n       y = \"Count\")\n\n\n\n\nWe’re looking pretty good! Ultimately; however, we want to find a generalized relationship between our outcome of interest and the independent variable that we think is an important driver of that outcome. Rather than focusing on building a model that perfectly predicts the average life expectancy of countries given their GDP per capita in 2021, we want to learn something about the general shape of this relationship. A linear regression model helps us do this.\nTo illustrate, let’s go back to our model:\n\\[\nLife\\ expectancy = 33.427 + 4.316 Logged\\ GDP\\ per\\ capita + \\epsilon\n\\]\nLet’s plot out the predicted average life expectancy for hypothetical countries with any logged GDP per capita within a plausible range:\n\naugment(m, newdata = tibble(log_gdp_per_cap = seq(0, 12, by = 0.01))) |&gt; \n  ggplot(aes(x = log_gdp_per_cap, y = .fitted)) + \n  geom_line() + \n  theme_minimal() + \n  labs(x = \"Logged GDP per capita (in current USD)\",\n       y = \"Predicted average life expectancy (in years)\")\n\n\n\n\nHere, we have used historical data that describe the actual average life expectancy of countries globally and their actual GDP per capita to build our understanding of an important factor associated with the overall health of a country’s citizens. In doing this, we have gained explanatory traction: there is a strong, positive association between a country’s GDP per capita and its average life expectancy. Countries with higher GDP per capita tend to have longer average life expectancy. We have also gained predictive power: for any given (logged) GDP per capita, we can predict what that country’s average life expectancy would be. Further, we can predict the change in a country’s average life expectancy that may result from a change in its GDP per capita.\nAll of this knowledge that we have gained rests on the strength of our model. Have we included all of the important drivers of a country’s average life expectancy? Have we used the right models of the relationship between those variables and average life expectancy? How much confidence do we have in our model’s ability to explain these relationships and to use those inputs to predict average life expectancy?\nOLS regression is one approach to finding this generalized relationship. Remember, an OLS regression finds the straight line that minimizes the distance between itself and all of the data points. To illustrate, let’s look back at our fitted model within the context of the data points used to generate it:\n\nggplot(gapminder_df, aes(x = log_gdp_per_cap, y = life_exp)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = F) + \n  theme_minimal() + \n  labs(x = \"Logged GDP per capita\",\n       y = \"Average life expectancy (years)\") + \n  scale_x_continuous(labels = label_dollar())\n\n\n\n\nThis is a strong and clean relationship: I can clearly see that countries with higher logged GDP per capita tend to have longer average life expectancies. This is incorporated into our model, which formalizes this positive relationship.\nThere are many different ways we can think about error, but before you apply any more complicated statistical tests you should take a look at your model in the context of your data. This really is the best way to determine whether your model is capturing the underlying relationship between your variables.\n\nError for each data point\nAn OLS regression finds the straight line that minimizes the distance between itself and all of the data points. We can look at how far the predicted value produced by our model is from each data point. This distance is called the residual. As above, we can use broom::augment() to find it:\n\naugment(m) |&gt; \n  select(life_exp, .fitted, .resid)\n\n# A tibble: 202 × 3\n   life_exp .fitted .resid\n      &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n 1     74.6    77.8 -3.17 \n 2     62.0    58.8  3.20 \n 3     61.6    66.1 -4.43 \n 4     76.5    71.2  5.22 \n 5     78.7    79.6 -0.898\n 6     75.4    73.5  1.94 \n 7     72.0    70.2  1.88 \n 8     78.5    75.5  2.98 \n 9     83.3    81.0  2.34 \n10     81.2    80.4  0.818\n# ℹ 192 more rows\n\n\nLet’s plot those differences to make them easier to digest:\n\nggplot(augment(m), aes(x = .resid)) + \n  geom_density() + \n  geom_vline(xintercept = 0) + \n  theme_minimal()\n\n\n\n\nIf our model perfectly predicted each country’s life expectancy, we would see no difference between the predicted and observed values. There would just be a very tall straight line at zero on the graph above.\n\n\n\n\n\n\nNote\n\n\n\nThis is not necessarily the goal. Random error is fine: the world is a complicated and chaotic place. However, we can use these residuals to evaluate our model. For example, you may notice that residuals for certain countries or groupings of countries are larger than the rest. This may prompt you to re-examine your data collection process (perhaps something strange went on) or to include another variable in your model that captures these differences.\n\n\nOur model hasn’t predicted life expectancy perfectly. Although most predictions are within a couple of years of the country’s observed average life expectancy, there are some that are very different (up to 10 or 15 years!). Where the model has got it wrong, it has tended to overestimate life expectancy (note that the peak of the density curve sits above zero).\n\n\nModel-wide tools\nSometimes we need a measure of the model’s overall accuracy. Here, I will refer you back to our notes from GVPT622: Relationships Between Two Variables.\n\n\n\n\n\n\nTip\n\n\n\nYou should be familiar with these tests: your colleagues will refer to them and reviewers may look at them. However, there is increasing recognition among political scientists of their limits. You will be far better off asking specific and critical questions of your data and your models than you will be by relying on many of these tests, which can sometimes be misleading.\nFor example, most of these tests are sensitive to the quantity of data you use. If you throw an extraordinary amount of data into your models, you will likely get a very good looking F-statistic and T-statistic, even if you have not fully uncovered the underlying relationship in your data. Our access to and ability to use very large amounts of data is only increasing. Issues with some of these tests will become more acute."
  },
  {
    "objectID": "content/01-introduction.html#step-6-evaluate-your-coefficients",
    "href": "content/01-introduction.html#step-6-evaluate-your-coefficients",
    "title": "Linear Regression: A Refresher",
    "section": "Step 6: Evaluate your coefficients",
    "text": "Step 6: Evaluate your coefficients\nAt this stage, we have a model that fits our data well. We now want to ask whether the relationship we have uncovered is statistically significantly different from no relationship. In other words, is this all just random noise?\nAssume that we have a pure random sample of our population. If we were to pull a different pure random sample from our population we would get a different set of coefficients. That’s totally fine! However, we need to work out what these different coefficients could plausibly be. Once we have done that, we can determine whether or not they include zero (or no relationship).\n\n\n\n\n\n\nNote\n\n\n\nFor the long version of this, return to the regression notes from GVPT622.\n\n\nWe use the coefficients we produced using our data as our best guesses:\n\ntidy(m) |&gt; \n  select(term:estimate)\n\n# A tibble: 2 × 2\n  term            estimate\n  &lt;chr&gt;              &lt;dbl&gt;\n1 (Intercept)        33.4 \n2 log_gdp_per_cap     4.32\n\n\nWe can then use the standard deviations around these best guesses to work out how spread out around this best guess alternative plausible coefficients would sit.\n\n\n\n\n\n\nTip\n\n\n\nThe standard deviation, (\\(s\\)), is calculated using two pieces of information: how well our line of best fit fits our observed data; and how much information (or data) we used to fit our model.\n\n\nYou can find each coefficient’s standard deviation using broom::tidy():\n\ntidy(m) |&gt; \n  select(term:std.error)\n\n# A tibble: 2 × 3\n  term            estimate std.error\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)        33.4      1.82 \n2 log_gdp_per_cap     4.32     0.203\n\n\nWe can now build out the plausible set of alternative coefficients:\n\ntibble(\n  x = rnorm(1e6, \n            mean = tidy(m) |&gt; filter(term == \"log_gdp_per_cap\") |&gt; pull(estimate),\n            sd = tidy(m) |&gt; filter(term == \"log_gdp_per_cap\") |&gt; pull(std.error))\n) |&gt; \n  ggplot(aes(x = x)) + \n  stat_halfeye(.width = c(.025, 0.975)) + \n  theme_minimal()\n\n\n\n\nIf we were to build an infinite number of linear regression models from an infinite number of pure random samples from the world (think: multiverse) we would get a series of coefficients that follow the distribution plotted above. Does this include zero (or no relationship)?\n\n\n\n\n\n\nNote\n\n\n\nRemember, regression coefficients tell us the expected change in our dependent variable changes for each one-unit increase in our independent variable, on average. If there is no association between our variables, there will be no change in our dependent variable and our regression coefficient will be zero.\n\n\nMost of the time you will be required to demonstrate that at least 95 percent of these plausible alternative coefficients do not include zero to claim statistical significance. In the graph above, this 95 percent is provided by the bar at the bottom of the density curve.\nTo work out whether 95 percent of these plausible alternative coefficients include zero we need to calculate the probability that we would observe the coefficient we found (here \\(\\beta_1 =\\) 4.316) if it were actually equal to zero. This probability is referred to as the p-value. We calculate it by finding our coefficient’s T-statistic.\n\n\n\n\n\n\nTip\n\n\n\nThe T-distribution is standard and centered at zero. We can transform our coefficient to its T-statistic and place it within this T-distribution to determine how likely we are to observe this or a more extreme value.\n\n\nbroom::tidy() provides both the T-statistic and p-value for our coefficients:\n\ntidy(m)\n\n# A tibble: 2 × 5\n  term            estimate std.error statistic  p.value\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)        33.4      1.82       18.3 1.17e-44\n2 log_gdp_per_cap     4.32     0.203      21.3 2.77e-53\n\n\nThe coefficient we observed is statistically significant: there is a very, very, very small chance (far less than 5% certainly) we would be able to pull a perfect random sample from our population and fit this model if there truly was no relationship between a country’s average life expectancy and its GDP per capita."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\n            Advanced Quantitative Methods for Political Science\n        ",
    "section": "",
    "text": "Advanced Quantitative Methods for Political Science\n        \n        \n            An introduction to multivariate analysis.\n        \n        \n            Spring 2024Department of Government and PoliticsUniversity of Maryland, College Park\n        \n    \n    \n      \n        \n        \n        \n      \n    \n\n\n\n\n\n\nProfessor\n\n   Dr Michael Hanmer\n   mhanmer@umd.edu\n\n\n\nTeaching Assistant\n\n   Harriet Goers\n   Chincoteague Building\n   hgoers@umd.edu\n   hgoers\n\n\n\n\n\nCourse details\n\n   January 24 - May 9\n   Thursday, 9:30 - 12:15 PM\n   Tydings Building, Room 1111\n\n\n\nLab details\n\n   TBD\n   TBD\n\n\n\nOffice hours\n\n   TBD\n   Zoom\n\n\n\n\nContacting me\nE-mail is the best ways to get in contact with me. I will try to respond to all course-related e-mails within 24 hours."
  }
]